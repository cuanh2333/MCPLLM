# V2 Log Analyzer Configuration Template

# LLM Configuration (Global defaults)
GROQ_API_KEY=your_groq_api_key_here
LLM_MODEL=llama-3.3-70b-versatile
LLM_TEMPERATURE=0
LLM_PROVIDER=groq
CHUNK_SIZE=50

# Google AI Configuration (optional - for using Gemini models)
GOOGLE_API_KEY=your_google_api_key_here

# V2: Agent-specific LLM providers (optional - defaults to LLM_PROVIDER)
# You can use different providers for different agents:
# - Groq: Fast, cheap, good for most tasks
# - Google: Gemini models, excellent for complex reasoning

# ANALYZE_AGENT_PROVIDER=groq
# TI_AGENT_PROVIDER=groq
# RECOMMEND_AGENT_PROVIDER=google
# REPORT_AGENT_PROVIDER=google

# V2: Agent-specific LLM models (optional - defaults to LLM_MODEL)
# Groq models: llama-3.3-70b-versatile, llama-3.1-8b-instant, openai/gpt-oss-120b, groq/compound
# Google models: gemini-2.5-pro, gemini-2.5-flash, gemini-2.5-flash-lite, gemini-2.0-flash-lite

# ANALYZE_AGENT_MODEL=llama-3.3-70b-versatile
# TI_AGENT_MODEL=llama-3.1-8b-instant
# RECOMMEND_AGENT_MODEL=gemini-2.5-flash
# REPORT_AGENT_MODEL=gemini-2.5-pro

# V2: Agent-specific temperatures (optional - defaults to LLM_TEMPERATURE)
# ANALYZE_AGENT_TEMPERATURE=0
# TI_AGENT_TEMPERATURE=0
# RECOMMEND_AGENT_TEMPERATURE=0.3
# REPORT_AGENT_TEMPERATURE=0.5

# MCP Configuration
MCP_SERVER_PATH=./mcp_server/log_server.py

# Cron Configuration (for run_cron_analysis.py)
V1_ANALYZER_API_URL=http://127.0.0.1:8000/analyze
SPLUNK_EARLIEST_TIME=-7h5m
SPLUNK_LATEST_TIME=-7h
ALERT_THRESHOLD=5
CRON_TIMEOUT=300

# Output Configuration
OUTPUT_DIR=./output
CSV_ENCODING=utf-8

# Splunk Configuration (optional - only if using Splunk)
SPLUNK_HOST=192.168.96.131
SPLUNK_PORT=8000
SPLUNK_USERNAME=anhtq23
SPLUNK_PASSWORD=@Csc2322003

# V2 Threat Intelligence API Keys
ABUSEIPDB_API_KEY=
VIRUSTOTAL_API_KEY=

# Additional API Keys (from existing project)
TELEGRAM_BOT_TOKEN=
TELEGRAM_CHAT_ID=
GOOGLE_API_KEY=

# V3: GenRule Agent Configuration
# GENRULE_AGENT_MODEL=llama-3.3-70b-versatile
# GENRULE_AGENT_TEMPERATURE=0.1

# V3: QueryRAG Agent Configuration
# QUERYRAG_AGENT_MODEL=llama-3.3-70b-versatile
# QUERYRAG_AGENT_TEMPERATURE=0.3

# V3: RAG Configuration
# RAG_SERVER_PATH=./mcp_server/rag_server.py
# RAG_TOP_K=5
# RAG_ALPHA=0.55

# V3: Feature Flags
# ENABLE_V3=true
# ENABLE_GENRULE=true
# ENABLE_QUERYRAG=true

# V4: LangGraph Configuration
USE_LANGGRAPH=true
GRAPH_VISUALIZATION=true
GRAPH_MAX_ITERATIONS=50
GRAPH_TIMEOUT=300

# V4: SupervisorAgent Configuration
USE_SUPERVISOR_AGENT=true
SUPERVISOR_AGENT_MODEL=llama-3.3-70b-versatile
SUPERVISOR_AGENT_TEMPERATURE=0.1

# V4: AssetAgent Configuration (Optional)
ENABLE_ASSET_AGENT=false
ASSET_AGENT_MODEL=llama-3.1-8b-instant
ASSET_AGENT_TEMPERATURE=0.2
ASSET_CACHE_TTL=3600
